# voice_ai_kiosk.py
import os
import sys
import time
import json
import csv
import re
from difflib import SequenceMatcher
from typing import List, Dict, Tuple, Optional, Any

from dotenv import load_dotenv
from openai import OpenAI

# ğŸ›‘ PyTorch ì¸ë•í„° / ë‹¤ì´ë„ˆëª¨ ë„ê¸° (cl ì»´íŒŒì¼ëŸ¬ ë¬¸ì œ ë°©ì§€ + ì•ˆì •ì„±)
os.environ["TORCHDYNAMO_DISABLE"] = "1"
os.environ["TORCHINDUCTOR_DISABLE"] = "1"

import torch
import torchaudio
import sounddevice as sd
import numpy as np

from faster_whisper import WhisperModel

# ====== ê¸°ì¡´ ì½”ë“œì˜ BASE_DIR / PROJECT_DIR ìœ ì§€ ======
BASE_DIR = r"C:\\Users\\ouner\\Desktop\\kiosk\\lee_kiosk"
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))

# âœ… wav í´ë”ë¥¼ ìŒì„± ì…ì¶œë ¥ í‘œì¤€ ìœ„ì¹˜ë¡œ ì‚¬ìš©
WAV_DIR = os.path.join(PROJECT_DIR, "wav")
os.makedirs(WAV_DIR, exist_ok=True)

# âœ… MeloTTS ê²½ë¡œë„ í”„ë¡œì íŠ¸ ê¸°ì¤€ìœ¼ë¡œ
MELO_PATH = os.path.join(PROJECT_DIR, "MeloTTS")
if MELO_PATH not in sys.path:
    sys.path.append(MELO_PATH)

from melo.api import TTS  # âœ… Melo TTS

# ------------------------------------------------
# 0. ê³µí†µ ì„¤ì •
# ------------------------------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âœ… Using device: {DEVICE}")

# HOT/ICE ê´€ë ¨ í‚¤ì›Œë“œ
HOT_KEYWORDS = {"í•«", "ëœ¨ê±°ìš´", "ë”°ëœ»í•œ"}
ICE_KEYWORDS = {"ì•„ì´ìŠ¤", "ì°¨ê°€ìš´", "ì‹œì›í•œ"}

# ------------------------------------------------
# 1. ëª¨ë¸ë“¤ ë¯¸ë¦¬ ë¡œë“œ (í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ 1ë²ˆë§Œ)
# ------------------------------------------------
print("ğŸ”Š Whisper ëª¨ë¸ ë¡œë“œ ì¤‘ (small, fp16/int8)...")
whisper = WhisperModel(
    "small",
    device=DEVICE,
    compute_type="float16" if DEVICE == "cuda" else "int8"
)

print("ğŸµ Melo TTS ë¡œë“œ ì¤‘...")
MELO_SPEED = 1.5
MELO_DEVICE = "cuda:0" if DEVICE == "cuda" else "cpu"

melo_tts = TTS(language="KR", device=MELO_DEVICE)
melo_speaker_ids = melo_tts.hps.data.spk2id  # ì˜ˆ: melo_speaker_ids["KR"]

print("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")

# ------------------------------------------------
# 2. OpenAI client (EEVE ëŒ€ì‹ )
# ------------------------------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

PARSE_ORDER_TOOL = {
    "type": "function",
    "name": "parse_order",
    "description": "í•œêµ­ì–´ ì¹´í˜ ì£¼ë¬¸ ë¬¸ì¥ì„ JSON ì£¼ë¬¸ ê°ì²´ë¡œ ë³€í™˜í•œë‹¤.",
    "parameters": {
        "type": "object",
        "properties": {
            "items": {
                "type": "array",
                "minItems": 1,
                "items": {
                    "type": "object",
                    "properties": {
                        "menu_name": {"type": "string", "minLength": 1},
                        "menu_quantity": {"type": "integer", "minimum": 1},
                        "menu_option": {"type": "string"},
                    },
                    "required": ["menu_name", "menu_quantity", "menu_option"],
                    "additionalProperties": False,
                },
            },
            "assistant_response": {"type": "string", "minLength": 1},
        },
        "required": ["items", "assistant_response"],
        "additionalProperties": False,
    },
}

# ------------------------------------------------
# 3. ìœ í‹¸ í•¨ìˆ˜ë“¤ (ë…¹ìŒ / STT / TTS)
# ------------------------------------------------
def record_to_file(filename: str, sec: float = 3.0, samplerate: int = 16000):
    """ë§ˆì´í¬ ë…¹ìŒ -> WAV ì €ì¥"""
    print("ğŸ™ ë…¹ìŒ ì‹œì‘... (ë§í•˜ì„¸ìš”!)")
    audio = sd.rec(
        int(sec * samplerate),
        samplerate=samplerate,
        channels=1,
        dtype="float32",
    )
    sd.wait()
    print("ğŸ™ ë…¹ìŒ ì¢…ë£Œ")

    audio_np = np.squeeze(audio)
    audio_tensor = torch.tensor(audio_np).unsqueeze(0)  # [1, T]
    torchaudio.save(filename, audio_tensor, samplerate)


@torch.inference_mode()
def stt_whisper(audio_path: str) -> str:
    """Whisperë¡œ ìŒì„± -> í…ìŠ¤íŠ¸"""
    t0 = time.time()
    segments, info = whisper.transcribe(
        audio_path,
        beam_size=1,
        vad_filter=True,
        vad_parameters={"min_silence_duration_ms": 500},
        without_timestamps=True,
        language="ko",
    )
    text = " ".join(seg.text.strip() for seg in segments).strip()
    print(f"â± Whisper ì¸ì‹ ì‹œê°„: {time.time() - t0:.2f}s")
    return text


@torch.inference_mode()
def speak_with_melo(text: str, out_path: str, speed: float = MELO_SPEED):
    """Melo TTSë¡œ í•œêµ­ì–´ ë¬¸ì¥ì„ ìŒì„±(WAV)ìœ¼ë¡œ ì €ì¥"""
    if len(text) > 120:
        print("ğŸ” TTS í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ì„œ ì• 120ìë§Œ ì½ìŠµë‹ˆë‹¤.")
        text = text[:120]

    t0 = time.time()
    speaker_id = melo_speaker_ids["KR"]
    melo_tts.tts_to_file(text, speaker_id, out_path, speed=speed)
    print(f"â± Melo TTS ì‹œê°„: {time.time() - t0:.2f}s")

# ------------------------------------------------
# 4. CSV ë¡œë”© (ì¸ì½”ë”© robust) - ë¼ì´íŠ¸ RAGì— ì‚¬ìš©
# ------------------------------------------------
def open_text_robust(path: str, newline: str = ""):
    encodings = ("utf-8-sig", "cp949", "euc-kr", "utf-8")
    last_err = None
    for enc in encodings:
        f = None
        try:
            f = open(path, "r", encoding=enc, newline=newline)
            f.readline()   # í—¤ë” ë””ì½”ë”© ê°•ì œ
            f.seek(0)
            return f
        except UnicodeDecodeError as e:
            last_err = e
            if f:
                f.close()
    raise last_err


def load_menu_names(menu_csv_path: str) -> List[str]:
    names: List[str] = []
    with open_text_robust(menu_csv_path, newline="") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames or "ì´ë¦„" not in reader.fieldnames:
            raise ValueError(f"data.csvì— 'ì´ë¦„' ì»¬ëŸ¼ì´ ì—†ìŒ. fieldnames={reader.fieldnames}")
        for row in reader:
            n = (row.get("ì´ë¦„") or "").strip()
            if n:
                names.append(n)

    seen = set()
    uniq = []
    for n in names:
        if n not in seen:
            seen.add(n)
            uniq.append(n)
    return uniq


def load_option_names(option_csv_path: str) -> List[str]:
    names: List[str] = []
    with open_text_robust(option_csv_path, newline="") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames or "kor_name" not in reader.fieldnames:
            raise ValueError(f"drink_price.csvì— 'kor_name' ì»¬ëŸ¼ì´ ì—†ìŒ. fieldnames={reader.fieldnames}")
        for row in reader:
            n = (row.get("kor_name") or "").strip()
            if n:
                names.append(n)

    seen = set()
    uniq = []
    for n in names:
        if n not in seen:
            seen.add(n)
            uniq.append(n)
    return uniq


MENU_CSV = os.path.join(PROJECT_DIR, "DATA", "data.csv")
OPTION_CSV = os.path.join(PROJECT_DIR, "DATA", "drink_price.csv")

# âœ… import ì‹œ 1ë²ˆë§Œ ë¡œë“œ (ê¸°ì¡´ì²˜ëŸ¼ â€œì´ˆê¸° ë¡œë”©â€ ìŠ¤íƒ€ì¼ ìœ ì§€)
MENU_NAMES: List[str] = load_menu_names(MENU_CSV)
OPTION_NAMES: List[str] = load_option_names(OPTION_CSV)

# ------------------------------------------------
# 5. ë¼ì´íŠ¸ RAG(Top-K í›„ë³´ ì£¼ì…) + ê·œì¹™ í›„ì²˜ë¦¬
# ------------------------------------------------
_KO_CLEAN_RE = re.compile(r"[^0-9a-zA-Zê°€-í£\s]")

def normalize_text(s: str) -> str:
    s = (s or "").lower().strip()
    s = _KO_CLEAN_RE.sub(" ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()

def top_k_candidates(query: str, candidates: List[str], k: int = 15) -> List[str]:
    nq = normalize_text(query).replace(" ", "")
    scored: List[Tuple[float, str]] = []
    for c in candidates:
        nc = normalize_text(c).replace(" ", "")
        base = similarity(nq, nc)
        if nc and nc in nq:
            base += 0.25
        if nq and nq in nc:
            base += 0.10
        scored.append((base, c))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [c for _, c in scored[:k]]

def ensure_candidates(cands: List[str], must: List[str], universe: List[str]) -> List[str]:
    s = set(cands)
    out = list(cands)
    uni = set(universe)
    for m in must:
        if m in uni and m not in s:
            out.insert(0, m)
            s.add(m)
    return out

NEG_WORDS = ["ë¹¼", "ë¹¼ì¤˜", "ë¹¼ê³ ", "ì—†ì´", "ì—†ê²Œ", "ì œì™¸", "ë„£ì§€", "ë„£ì§€ë§ˆ", "ë§ì•„", "ì•ˆ ë„£", "ì•ˆë„£"]
POS_WORDS = ["ë„£ì–´", "ë„£ì–´ì¤˜", "ì¶”ê°€", "ì¶”ê°€í•´", "ì¶”ê°€í•´ì¤˜", "ì˜¬ë ¤", "ì˜¬ë ¤ì¤˜", "ìˆê²Œ"]

def _contains_any(text: str, words: List[str]) -> bool:
    t = normalize_text(text).replace(" ", "")
    return any(normalize_text(w).replace(" ", "") in t for w in words)

def should_force_zero_cider(user_text: str) -> bool:
    t = normalize_text(user_text).replace(" ", "")
    if "ì œë¡œì‚¬ì´ë‹¤" not in t:
        return False
    return any(x in t for x in ["ë³€ê²½", "ë°”ê¿”", "ë°”ê¾¸", "ëŒ€ì‹ ", "ìœ¼ë¡œ", "ë¡œ"])

def intent_whip(user_text: str) -> Optional[str]:
    t = normalize_text(user_text).replace(" ", "")
    if ("íœ˜í•‘" not in t) and ("íœ˜í•‘í¬ë¦¼" not in t):
        return None
    if _contains_any(user_text, NEG_WORDS):
        return "íœ˜í•‘(X)"
    if _contains_any(user_text, POS_WORDS):
        return "íœ˜í•‘(O)"
    return "íœ˜í•‘(O)"

def intent_cinnamon(user_text: str) -> Optional[str]:
    t = normalize_text(user_text).replace(" ", "")
    if "ì‹œë‚˜ëª¬" not in t:
        return None
    if _contains_any(user_text, NEG_WORDS):
        return "ì‹œë‚˜ëª¬(X)"
    if _contains_any(user_text, POS_WORDS):
        return "ì‹œë‚˜ëª¬(O)"
    return "ì‹œë‚˜ëª¬(O)"

def best_match(value: str, candidates: List[str]) -> Optional[str]:
    if not candidates:
        return None
    nv = normalize_text(value)
    scored = [(similarity(nv, normalize_text(c)), c) for c in candidates]
    scored.sort(reverse=True, key=lambda x: x[0])
    return scored[0][1]

def attach_option_first(items: List[Dict[str, Any]], option_value: str):
    if items:
        items[0]["menu_option"] = option_value

def apply_hot_ice_preference(user_text: str, menu_universe: List[str], items: List[Dict[str, Any]]) -> None:
    t = normalize_text(user_text).replace(" ", "")
    hot = any(normalize_text(x).replace(" ", "") in t for x in HOT_KEYWORDS)
    ice = any(normalize_text(x).replace(" ", "") in t for x in ICE_KEYWORDS)

    uni = set(menu_universe)
    for it in items:
        name = (it.get("menu_name") or "").strip()
        if not name:
            continue

        if hot and not name.endswith("(HOT)"):
            hot_name = f"{name}(HOT)"
            if hot_name in uni:
                it["menu_name"] = hot_name

        if ice and name.endswith("(HOT)"):
            base = name[:-5]  # remove "(HOT)"
            if base in uni:
                it["menu_name"] = base

def expand_to_single_cups(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for it in items:
        mn = str(it.get("menu_name", "")).strip()
        mo = str(it.get("menu_option", "")).strip()
        mq = it.get("menu_quantity", 1)
        try:
            mq = int(mq)
        except (TypeError, ValueError):
            mq = 1
        if mq < 1:
            mq = 1

        for _ in range(mq):
            out.append({"menu_name": mn, "menu_quantity": 1, "menu_option": mo})
    return out

def option_to_spoken(user_text: str, opt: str) -> str:
    t = normalize_text(user_text).replace(" ", "")
    opt = (opt or "").strip()

    if opt == "íœ˜í•‘(O)":
        return "íœ˜í•‘í¬ë¦¼ ë„£ì–´ì¤˜" if "íœ˜í•‘í¬ë¦¼" in t else "íœ˜í•‘ ë„£ì–´ì¤˜"
    if opt == "íœ˜í•‘(X)":
        return "íœ˜í•‘í¬ë¦¼ ë¹¼ì¤˜" if "íœ˜í•‘í¬ë¦¼" in t else "íœ˜í•‘ ë¹¼ì¤˜"

    if opt == "ì‹œë‚˜ëª¬(O)":
        return "ì‹œë‚˜ëª¬ ë„£ì–´ì¤˜"
    if opt == "ì‹œë‚˜ëª¬(X)":
        return "ì‹œë‚˜ëª¬ ë¹¼ì¤˜"

    if opt == "ì œë¡œì‚¬ì´ë‹¤" and should_force_zero_cider(user_text):
        return "ì œë¡œì‚¬ì´ë‹¤ë¡œ ë³€ê²½"

    return opt

def build_assistant_response(user_text: str, items_single_cup: List[Dict[str, Any]]) -> str:
    if not items_single_cup:
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì£¼ë¬¸ì„ í™•ì¸í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”? ê·¸ëŒ€ë¡œ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

    counter: Dict[Tuple[str, str], int] = {}
    order_keys: List[Tuple[str, str]] = []

    for it in items_single_cup:
        name = (it.get("menu_name") or "").strip()
        opt = (it.get("menu_option") or "").strip()
        key = (name, opt)
        if key not in counter:
            counter[key] = 0
            order_keys.append(key)
        counter[key] += 1

    parts: List[str] = []
    for (name, opt) in order_keys:
        qty = counter[(name, opt)]
        spoken_opt = option_to_spoken(user_text, opt)

        if not spoken_opt:
            parts.append(f"{name} {qty}ì”")
        else:
            parts.append(f"{name} {spoken_opt} {qty}ì”")

    if len(parts) == 1:
        mid = parts[0]
    elif len(parts) == 2:
        mid = f"{parts[0]}ê³¼ {parts[1]}"
    else:
        mid = ", ".join(parts[:-1]) + f" ê·¸ë¦¬ê³  {parts[-1]}"

    return f"ì†ë‹˜, ë§ì”€í•˜ì‹  {mid} ê·¸ëŒ€ë¡œ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

def postprocess_with_candidates(
    user_text: str,
    data: Dict[str, Any],
    menu_candidates: List[str],
    option_candidates: List[str],
    menu_universe: List[str],
) -> Dict[str, Any]:
    items = data.get("items")
    if not isinstance(items, list):
        items = []

    fixed: List[Dict[str, Any]] = []
    for it in items:
        if not isinstance(it, dict):
            continue

        mn = str(it.get("menu_name", "")).strip()
        mo = str(it.get("menu_option", "")).strip()
        mq = it.get("menu_quantity", 1)

        try:
            mq = int(mq)
        except (TypeError, ValueError):
            mq = 1
        if mq < 1:
            mq = 1

        if mn not in menu_candidates:
            mn = best_match(mn, menu_candidates) or (menu_candidates[0] if menu_candidates else mn)

        if mo not in option_candidates:
            mo = best_match(mo, option_candidates) or ""

        fixed.append({"menu_name": mn, "menu_quantity": mq, "menu_option": mo})

    if not fixed:
        fallback_menu = menu_candidates[0] if menu_candidates else "ì•„ë©”ë¦¬ì¹´ë…¸"
        fixed = [{"menu_name": fallback_menu, "menu_quantity": 1, "menu_option": ""}]

    # HOT/ICE ì˜ë„ ë³´ì •
    apply_hot_ice_preference(user_text, menu_universe, fixed)

    # ê·œì¹™ ê¸°ë°˜ ì˜µì…˜ ê°•ì œ
    if should_force_zero_cider(user_text) and "ì œë¡œì‚¬ì´ë‹¤" in option_candidates:
        attach_option_first(fixed, "ì œë¡œì‚¬ì´ë‹¤")

    w = intent_whip(user_text)
    if w and w in option_candidates:
        attach_option_first(fixed, w)

    c = intent_cinnamon(user_text)
    if c and c in option_candidates:
        attach_option_first(fixed, c)

    fixed_single = expand_to_single_cups(fixed)
    assistant_response = build_assistant_response(user_text, fixed_single)

    return {"items": fixed_single, "assistant_response": assistant_response}

def parse_order_light_rag(
    text: str,
    menu_names: List[str],
    option_names: List[str],
    model: str = "gpt-4o-mini",
    menu_top_k: int = 20,
    option_top_k: int = 20,
) -> Dict[str, Any]:
    menu_candidates = top_k_candidates(text, menu_names, k=menu_top_k)
    option_candidates = top_k_candidates(text, option_names, k=option_top_k)

    # Top-Kì— ì•ˆ ë“¤ì–´ê°€ë„ ê·œì¹™ìš© ì˜µì…˜ì€ í›„ë³´ì— ê°•ì œë¡œ í¬í•¨
    must_opts = ["ì œë¡œì‚¬ì´ë‹¤", "íœ˜í•‘(O)", "íœ˜í•‘(X)", "ì‹œë‚˜ëª¬(O)", "ì‹œë‚˜ëª¬(X)"]
    option_candidates = ensure_candidates(option_candidates, must_opts, option_names)

    option_candidates_plus = option_candidates + [""]  # ë¹ˆ ì˜µì…˜ í—ˆìš©

    instructions = f"""
ë„ˆëŠ” ì¹´í˜ í‚¤ì˜¤ìŠ¤í¬ ì£¼ë¬¸ íŒŒì„œë‹¤.
- ë°˜ë“œì‹œ parse_order í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œë§Œ ë‹µí•´ë¼. (ë§ë¡œ ì„¤ëª… ê¸ˆì§€)
- itemsëŠ” ë¹„ìš°ì§€ ë§ˆë¼. ìµœì†Œ 1ê°œ ì±„ì›Œë¼.
- ìˆ˜ëŸ‰ì´ ì—†ìœ¼ë©´ menu_quantity=1
- ì˜µì…˜ì´ ì—†ìœ¼ë©´ menu_option=""

[ì¤‘ìš”: í›„ë³´ ì œí•œ]
- menu_nameì€ ì•„ë˜ [MENU_CANDIDATES] ëª©ë¡ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì„ íƒí•´ë¼.
- menu_optionì€ ì•„ë˜ [OPTION_CANDIDATES] ëª©ë¡ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì„ íƒí•´ë¼.
- ëª©ë¡ì— ì—†ëŠ” ê°’ì€ ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼. ì• ë§¤í•˜ë©´ ê°€ì¥ ê°€ê¹Œìš´ í›„ë³´ë¥¼ ì„ íƒí•´ë¼.

[MENU_CANDIDATES]
{json.dumps(menu_candidates, ensure_ascii=False)}

[OPTION_CANDIDATES]
{json.dumps(option_candidates_plus, ensure_ascii=False)}
""".strip()

    resp = client.responses.create(
        model=model,
        instructions=instructions,
        input=text,
        tools=[PARSE_ORDER_TOOL],
        tool_choice={"type": "function", "name": "parse_order"},
        temperature=0.0,
    )

    for out in resp.output:
        if out.type == "function_call" and out.name == "parse_order":
            data = json.loads(out.arguments)
            return postprocess_with_candidates(
                user_text=text,
                data=data,
                menu_candidates=menu_candidates,
                option_candidates=option_candidates_plus,
                menu_universe=menu_names,
            )

    raise RuntimeError("parse_order tool call not found")

# ------------------------------------------------
# 6. í‚¤ì˜¤ìŠ¤í¬ìš© ë˜í¼ í´ë˜ìŠ¤ (ë©”ì„œë“œ/ì´ë¦„ ìœ ì§€)
# ------------------------------------------------
class VoiceAIKiosk:
    """
    í‚¤ì˜¤ìŠ¤í¬ ë©”ì¸ ì½”ë“œ(kiosk_t.py)ì—ì„œ ì‚¬ìš©í•  ë˜í¼.
    - Whisper + Melo TTSëŠ” import ì‹œ ì´ë¯¸ ë¡œë“œë¨
    - EEVE ëŒ€ì‹  OpenAI ë¼ì´íŠ¸ RAG ì‚¬ìš©
    """

    def __init__(self):
        print("âœ… VoiceAIKiosk ì´ˆê¸°í™” (ëª¨ë¸ ì´ë¯¸ ë¡œë“œë¨)")

    def record_and_stt(self, sec: float = 3.0, in_filename: str = "input.wav") -> str:
        wav_path = os.path.join(WAV_DIR, in_filename)
        record_to_file(wav_path, sec=sec)
        text = stt_whisper(wav_path)
        return text

    def parse_menu_json(self, user_text: str) -> dict:
        """
        user_text â†’ OpenAI(ë¼ì´íŠ¸ RAG) â†’
        {
          "items": [ {menu_name, menu_quantity(í•­ìƒ1), menu_option}, ... ],
          "assistant_response": "..."
        }
        """
        try:
            result = parse_order_light_rag(
                text=user_text,
                menu_names=MENU_NAMES,
                option_names=OPTION_NAMES,
                model="gpt-4o-mini",
            )

            if not isinstance(result, dict):
                raise ValueError("LLM result is not a dict")

            # items íƒ€ì… ì•ˆì „ì¥ì¹˜
            items = result.get("items", [])
            if not isinstance(items, list):
                result["items"] = []

            # assistant_response ì•ˆì „ì¥ì¹˜
            ar = result.get("assistant_response", "")
            if not isinstance(ar, str) or not ar.strip():
                result["assistant_response"] = "ì†ë‹˜, ì£¼ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ê·¸ëŒ€ë¡œ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

            return result

        except Exception as e:
            print("â— parse_menu_json ì‹¤íŒ¨:", e)
            return {
                "items": [
                    {
                        "menu_name": "",
                        "menu_quantity": 1,
                        "menu_option": ""
                    }
                ],
                "assistant_response": "ì£„ì†¡í•©ë‹ˆë‹¤, ì£¼ë¬¸ ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”? ê·¸ëŒ€ë¡œ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            }

    def make_tts(self, text: str, out_filename: str = "response.wav", speed: float = MELO_SPEED) -> str:
        out_path = os.path.join(WAV_DIR, out_filename)
        speak_with_melo(text, out_path, speed=speed)
        return out_path

    def run_voice_order_once(self, record_sec: float = 3.0) -> dict:
        wav_path = os.path.join(WAV_DIR, "input.wav")
        record_to_file(wav_path, sec=record_sec)
        user_text = stt_whisper(wav_path)
        print("ğŸ“ STT ê²°ê³¼:", user_text)

        if not user_text:
            resp_text = "ìŒì„±ì„ ì˜ ë“£ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”? ê·¸ëŒ€ë¡œ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            return {
                "ok": False,
                "reason": "stt_empty",
                "stt_text": "",
                "items": [],
                "assistant_response": resp_text,
                "tts_path": "",
            }

        result = self.parse_menu_json(user_text)
        items = result.get("items", [])
        assistant_response = result.get("assistant_response", "")

        out_wav = os.path.join(WAV_DIR, "response.wav")
        speak_with_melo(assistant_response, out_wav)

        return {
            "ok": True,
            "reason": "ok",
            "stt_text": user_text,
            "items": items,
            "assistant_response": assistant_response,
            "tts_path": out_wav,
        }
